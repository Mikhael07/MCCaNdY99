{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mikhael07/MCCaNdY99/blob/main/docs/notebooks/Training_and_inference_using_Google_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqgZlwEgwqmK"
      },
      "source": [
        "# Training and inference on your own data using Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xp-A8Oc80Q"
      },
      "source": [
        "In this notebook we'll install SLEAP, import training data into Colab using [Google Drive](https://www.google.com/drive), and run training and inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX9noEb8m8re"
      },
      "source": [
        "## Install SLEAP\n",
        "Note: Before installing SLEAP check [SLEAP releases](https://github.com/talmolab/sleap/releases) page for the latest version."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n"
      ],
      "metadata": {
        "id": "Lxn5Ndpn3l0g",
        "outputId": "ab0693a9-a8a2-4aae-a8f8-c6cc8c3e1acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "print(\"OpenCV version:\", cv2.__version__)"
      ],
      "metadata": {
        "id": "O3VG4iDe6W_1",
        "outputId": "3b7990c4-44be-4051-e34b-91a1315a3279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV version: 4.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]>=1.3.3\""
      ],
      "metadata": {
        "id": "0L2079jV-qME",
        "outputId": "56049c63-ccea-48a9-b98b-cd2ba6e40c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7jrgUksLtR"
      },
      "source": [
        "## Import training data into Colab with Google Drive\n",
        "We'll first prepare and export the training data from SLEAP, then upload it to Google Drive, and then mount Google Drive  into this Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwpEwrxYdLMR"
      },
      "source": [
        "### Create and export the training job package\n",
        "A self-contained **training job package** contains a .slp file with labeled data and images which will be used for training, as well as .json training configuration file(s).\n",
        "\n",
        "A training job package can be exported in the SLEAP GUI fron the \"Run Training..\" dialog under the \"Predict\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApaDWxW4dLMS"
      },
      "source": [
        "### Upload training job package to Google Drive\n",
        "To be consistent with the examples in this notebook, name the SLEAP project `colab` and create a directory called `sleap` in the root of your Google Drive. Then upload the exported training job package `colab.slp.training_job.zip` into `sleap` directory.\n",
        "\n",
        "If you place your training pckage somewhere else, or name it differently, adjust the paths/filenames/parameters below accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HCGgy4kdLMS",
        "tags": []
      },
      "source": [
        "### Mount your Google Drive\n",
        "Mounting your Google Drive will allow you to accessed the uploaded training job package in this notebook. When prompted to log into your Google account, give Colab access and the copy the authorization code into a field below (+ hit 'return')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBWjF4jpMG2N",
        "outputId": "add47e00-6d82-443d-9c11-31426447f0a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhv_gsdJzaq"
      },
      "source": [
        "Let's set your current working directory to the directory with your training job package and unpack it there. Later on the output from training (i.e., the models) and from interence (i.e., predictions) will all be saved in this directory as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umui-gI2rBz",
        "outputId": "38a9f3db-2f72-4774-b82f-91917b1e1d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  labels.v002.slp.training_job.zip\n",
            "  inflating: inference-script.sh     \n",
            "  inflating: jobs.yaml               \n",
            "  inflating: labels.v002.pkg.slp     \n",
            "  inflating: single_instance.json    \n",
            "  inflating: train-script.sh         \n",
            "inference-script.sh  labels.v002.pkg.slp\t       single_instance.json\n",
            "jobs.yaml\t     labels.v002.slp.training_job.zip  train-script.sh\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/sleap\")\n",
        "!unzip labels.v002.slp.training_job.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "Let's train a model with the training profile (.json file) and the project data (.slp file) you have exported from SLEAP.\n",
        "\n",
        "\n",
        "### Note on training profiles\n",
        "Depending on the pipeline you chose in the training dialog, the config filename(s) will be:\n",
        "\n",
        "- for a **bottom-up** pipeline approach: `multi_instance.json` (this is the pipeline we assume here),\n",
        "\n",
        "- for a **top-down** pipeline, you'll have a different profile for each of the models: `centroid.json` and `centered_instance.json`,\n",
        "\n",
        "- for a **single animal** pipeline: `single_instance.json`.\n",
        "\n",
        "\n",
        "### Note on training process\n",
        "When you start training, you'll first see the training parameters and then the training and validation loss for each training epoch.\n",
        "\n",
        "As soon as you're satisfied with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference.\n",
        "\n",
        "If you don't stop training, it will run for 200 epochs or until validation loss fails to improve for some number of epochs (controlled by the early_stopping fields in the training profile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QKf6qzMqNBUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873a697b-c97b-4bb0-976b-99f78ad941da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: sleap-train: command not found\n"
          ]
        }
      ],
      "source": [
        "!sleap-train single_instance.json colab.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "If instead of bottom-up you've chosen the top-down pipeline (with two training configs), you would need to invoke two separate training jobs in sequence:\n",
        "\n",
        "- `!sleap-train centroid.json colab.pkg.slp`\n",
        "- `!sleap-train centered_instance.json colab.pkg.slp`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "## Run inference to predict instances\n",
        "\n",
        "Once training finishes, you'll see a new directory (or two new directories for top-down training pipeline) containing all the model files SLEAP needs to use for inference.\n",
        "\n",
        "Here we'll use the created model files to run inference in two modes:\n",
        "\n",
        "- predicting instances in suggested frames from the exported .slp file\n",
        "\n",
        "- predicting and tracking instances in uploaded video\n",
        "\n",
        "You can also download the trained models for running inference from the SLEAP GUI on your computer (or anywhere else).\n",
        "\n",
        "### Predicting instances in suggested frames\n",
        "This mode of predicting instances is useful for accelerating the manual labeling work; it allows you to get early predictions on suggested frames and merge them back into the project for faster labeling.\n",
        "\n",
        "Here we assume you've trained a bottom-up model and that the model files were written in directory named `colab_demo.bottomup`; later in this notebook we'll also show how to run inference with the pair of top-down models instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-yzGXnNwqmN"
      },
      "outputs": [],
      "source": [
        "!sleap-track \\\n",
        "    -m colab_demo.bottomup \\\n",
        "    --only-suggested-frames \\\n",
        "    -o colab.predicted_suggestions.slp \\\n",
        "    colab.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cabfifeBwqmO"
      },
      "source": [
        "Now, you can download the generated `colab.predicted_suggestions.slp` file and merge it into your labeling project (**File -> Merge into Project...** from the GUI) to get new predictions for your suggested frames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTObpsCmwqmO"
      },
      "source": [
        "### Predicting and tracking instances in uploaded video\n",
        "Let's first upload the video we want to run inference on and name it `colab_demo.mp4`. (If your video is not named `colab_demo.mp4`, adjust the names below accordingly.)\n",
        "\n",
        "For this demo we'll just get predictions for the first 200 frames (or you can adjust the --frames parameter below or remove it to run on the whole video)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLtjtq9E1Znr"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.bottomup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, it will save the predictions in a file which can be opened in the GUI as a SLEAP project file. The file will be in the same directory as the video and the filename will be `{video filename}.predictions.slp`.\n",
        "\n",
        "Let's inspect the predictions file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfmNMSt-vS7"
      },
      "outputs": [],
      "source": [
        "!sleap-inspect colab_demo.mp4.predictions.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJ2kNBK-w6k"
      },
      "source": [
        "You can copy this file from your Google Drive to a local drive and open it in the SLEAP GUI app (or open it directly if you have your Google Drive mounted on your local machine). If the video is in the same directory as the predictions file, SLEAP will automatically find it; otherwise, you'll be prompted to locate the video (since the path to the video on your local machine will be different than the path to the video on Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-NoJOFvYHM"
      },
      "source": [
        "### Inference with top-down models\n",
        "\n",
        "If you trained the pair of models needed for top-down inference, you can call `sleap-track` with `-m path/to/model` for each model, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKnMc1qvim7"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.centered_instance \\\n",
        "    -m colab_demo.centroid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_and_inference_using_Google_Drive.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}